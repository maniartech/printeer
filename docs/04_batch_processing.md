# Chapter 4: Batch Processing

For enterprise use cases—such as generating 10,000 monthly invoices or archiving an entire documentation site—Printeer includes a dedicated **Batch Processor**.

The Batch Processor is designed for:
-   **High Concurrency**: Processing multiple URLs in parallel.
-   **Resource Safety**: Queue-based scheduling that respects memory and CPU limits.
-   **Resilience**: Retry logic and error reporting.

## The Batch CLI Command

```bash
printeer batch <job_file> [options]
```

**Options:**
-   `-o, --output-dir <dir>`: Output directory (default: `./output`).
-   `-c, --concurrency <n>`: Number of parallel browser tabs (default: 3).
-   `--continue-on-error`: If one job fails, keep processing the rest.
-   `--report <format>`: Generate a final report (`json`, `csv`, or `html`).
-   `--report-file <path>`: Where to save the report.
-   `--retry <attempts>`: Retry attempts for failed jobs (default: 2).
-   `--progress`: Show progress bar.
-   `--dry-run`: Validate batch file without processing.
-   `--max-memory <amount>`: Maximum memory usage (e.g., "2GB").
-   `--cleanup`: Cleanup temporary files after processing.
-   `-q, --quiet`: Suppress output except errors.
-   `--verbose`: Verbose output.

## Defining Jobs

Batch jobs can be defined in **JSON**, **YAML**, or **CSV**.

### JSON Format (Recommended)
JSON offers the most flexibility, allowing nested configuration overrides per job.

```json
[
  {
    "id": "invoice-101",
    "url": "https://store.com/invoice/101",
    "output": "invoices/101.pdf"
  },
  {
    "id": "invoice-102",
    "url": "https://store.com/invoice/102",
    "output": "invoices/102.pdf",
    "preset": "legal-doc"  // Use a specific preset for this job
  }
]
```

### CSV Format (Simplest)
Best for exporting from Excel or simple lists.

```csv
id,url,output
page-1,https://site.com/1,page1.pdf
page-2,https://site.com/2,page2.pdf
```

## Variable Expansion

Printeer supports variable substitution in batch files, which is powerful for generating jobs programmatically.

```json
{
  "jobs": [
    {
      "id": "report-{region}",
      "url": "https://site.com/report?region={region}",
      "output": "reports/{region}.pdf",
      "variables": {
        "region": ["US", "EU", "APAC"]
      }
    }
  ]
}
```

In this example, Printeer will automatically expand this single entry into **3 separate jobs** (`report-US`, `report-EU`, `report-APAC`).

## Dependency Scheduling

The batch processor supports a Directed Acyclic Graph (DAG) for job dependencies. This is useful if Job B cannot run until Job A has finished (e.g., generating a summary PDF that depends on data generated by previous steps).

Add a `dependencies` array to any job:

```json
[
  { "id": "job-a", ... },
  { "id": "job-b", ..., "dependencies": ["job-a"] }
]
```

Printeer's scheduler ensures `job-b` sits in the queue until `job-a` completes successfully.

## Resource & Performance Management

Batch processing is intensive. Printeer uses a **Browser Pool** strategy by default in batch mode.

1.  **Pool Size**: Controlled by `--concurrency`. If set to 5, Printeer maintains up to 5 open browser pages/contexts.
2.  **Instance Reuse**: It does *not* restart Chrome for every URL. It reuses the browser instance to save 300ms-1s of startup time per job.
3.  **Memory Protection**: The batch processor monitors heap usage. If a job spikes memory usage critical levels, the worker is restarted to prevent a full crash.

### Example: High-Throughput Run

To convert 1,000 pages safely:

```bash
printeer batch all-pages.json \
  --concurrency 8 \
  --output-dir ./dist \
  --continue-on-error \
  --report json \
  --report-file ./run-stats.json
```

This will run 8 parallel conversions, log any failures to `run-stats.json`, and ensure the process finishes even if individual pages timeout.
